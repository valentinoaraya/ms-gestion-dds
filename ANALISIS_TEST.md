## ğŸ“Š AnÃ¡lisis del Microservicio y Mejoras Propuestas

Se realizÃ³ un anÃ¡lisis de rendimiento del microservicio mediante un Spike Test con k6, simulando un escenario de carga pico con hasta 100 usuarios virtuales durante 40 segundos. El objetivo fue evaluar estabilidad, latencia, throughput y resistencia ante cargas abruptas.

### ğŸ§ª Resultados del Spike Test

Los resultados principales fueron los siguientes:

- **Requests procesados:** 7695
- **Errores:** 0% (http_req_failed = 0.00%)
- **Latencia promedio:** 4.71 ms
- **p(95) de latencia:** 8.01 ms
- **Latencia mÃ¡xima:** 45 ms
- **Throughput:** 36.57 requests/seg
- **Checks totales:** 7695 (100% exitosos)
- **Status Codes:** 200 en todas las respuestas vÃ¡lidas

Imagen de los Resultados
![Resultados K6](/k6/Mediciones%20K6.jpg)

Todas las condiciones del test fueron cumplidas:

- `http_req_duration: p(95)<500` â†’ âœ”ï¸ 8 ms
- `http_req_failed: rate<0.1` â†’ âœ”ï¸ 0%
- `successful_requests: count>400` â†’ âœ”ï¸ 1539

### âœ”ï¸ Conclusiones del test

El microservicio mostrÃ³:

- **Excelente tiempo de respuesta**, con picos menores a 50 ms incluso bajo carga mÃ¡xima.
- **Estabilidad total**, sin fallas de servidor ni tiempos de espera.
- **Muy buena escalabilidad**, sin seÃ±ales de saturaciÃ³n.
- **Respuestas consistentes**, sin variaciones anÃ³malas en los endpoints testeados.

El diseÃ±o actual estÃ¡ preparado para operar correctamente dentro de una arquitectura de microservicios con trÃ¡fico alto o variable.

### ğŸš€ Mejora Propuesta: ImplementaciÃ³n de Rate Limit

Aunque el rendimiento es sÃ³lido, existe una mejora importante recomendada para un entorno de microservicios real:

#### ğŸ”’ Implementar un Rate Limit por IP o por ruta crÃ­tica

El microservicio no cuenta actualmente con limitaciÃ³n de peticiones por segundo, lo que puede permitir:

- Ataques de flooding o consumo excesivo del endpoint
- Mal uso accidental desde un microservicio externo
- SaturaciÃ³n de PostgreSQL o Redis bajo cargas sostenidas

#### ğŸ¯ RecomendaciÃ³n prÃ¡ctica

Agregar un middleware de Rate Limiting ligero, por ejemplo:

- **express-rate-limit** en Node.js
- **LÃ­mite sugerido:** 30â€“60 requests por minuto por IP, ajustable segÃºn entorno
- **Aplicar solo en rutas crÃ­ticas** como consultas masivas
- **Excluir** `/health` y endpoints internos

Esto permitirÃ­a:

- Proteger la base de datos
- Evitar sobrecargas accidentales
- Mejorar la resiliencia total del sistema
- Alinearse con los patrones de microservicios solicitados (Rate Limit)

### ğŸ”¢ RecomendaciÃ³n: CÃ¡lculo de RÃ©plicas Necesarias

BasÃ¡ndose en los resultados del spike test, es posible calcular cuÃ¡ntas rÃ©plicas son necesarias para soportar una carga especÃ­fica:

#### Capacidad por instancia

El test mostrÃ³ que cada instancia puede procesar aproximadamente:
- **36 req/s por instancia**

#### Ejemplo de cÃ¡lculo

Si necesitas soportar **100 req/s**, el cÃ¡lculo es:

```
100 req/s Ã· 36 req/s = 2.7 â†’ 3 rÃ©plicas
```

#### FÃ³rmula general

```
NÃºmero de rÃ©plicas = Carga objetivo (req/s) Ã· 36 req/s
```

Siempre redondea hacia arriba para tener un margen de seguridad.

Este anÃ¡lisis basado en datos empÃ­ricos facilita la justificaciÃ³n del nÃºmero de rÃ©plicas en la configuraciÃ³n de producciÃ³n y permite dimensionar correctamente la infraestructura segÃºn las necesidades de trÃ¡fico esperadas.